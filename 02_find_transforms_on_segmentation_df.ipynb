{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates a set of transformations based on segmented masks.\n",
    "\n",
    "Input:\n",
    "- pathway to a directory containing segmented labels\n",
    "- pathway to a directory containing data frames\n",
    "- list of wells to process\n",
    "- downscale factor (1 - no downscaling, 2 - will make images 4 times smaller)\n",
    "\n",
    "Output:\n",
    "- a set of transforms for each well saved as pkl files\n",
    "\n",
    "Downscale factor allows for calculations of transformations on smaller images (for huge images StackReg may run out of RAM - downscaling prevents solves the issue).\n",
    "\n",
    "Optionally you can visualize alignment on downscaled images (visualization uses Napari)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in info about the experiment to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathway to a directory with segmented masks for alignment (ex. im_segmented)\n",
    "path_labels = r''\n",
    "\n",
    "# pathway to a directory with data frames (ex. df)\n",
    "path_df = r''\n",
    "\n",
    "# list of wells to be processed (usually names as 'A3')\n",
    "well_list = ['D4'] \n",
    "\n",
    "# pathway to save transformations (ex. df)\n",
    "path_save = r''\n",
    "\n",
    "# specify a downscaling factor for the alignment\n",
    "downscale_factor = 1 \n",
    "\n",
    "# specify anchor round (to which alignment will be done)\n",
    "anchor_round_selected = 2 # as named in the directory, default should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.transform import downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pystackreg import StackReg\n",
    "import pystackreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path_labels,myWell):\n",
    "    \n",
    "    labels_list = [x for x in os.listdir(os.path.join(path_labels,myWell)) if 'tif' in x]\n",
    "    labels_list.sort()\n",
    "\n",
    "    labels_im_list = []\n",
    "    for lab_im_name in labels_list:\n",
    "\n",
    "        lab_im = plt.imread(os.path.join(path_labels,myWell,lab_im_name))\n",
    "        labels_im_list.append(lab_im)\n",
    "\n",
    "    labels_im = np.array(labels_im_list)\n",
    "    \n",
    "    return labels_im\n",
    "\n",
    "def rescale_transforms(tmat_org,downscale_factor):\n",
    "     \n",
    "    # rescale transformation\n",
    "    if downscale_factor != 1:\n",
    "        \n",
    "        tmat = []\n",
    "\n",
    "        for tranform_matrix in tmat_org:\n",
    "\n",
    "            eu_transform_small = transform.EuclideanTransform(tranform_matrix)\n",
    "\n",
    "            eu_transform = transform.EuclideanTransform(translation = eu_transform_small.translation * downscale_factor,\n",
    "                                                        rotation = eu_transform_small.rotation)\n",
    "\n",
    "            tmat.append(eu_transform)\n",
    "            \n",
    "    else:\n",
    "        tmat = tmat_org\n",
    "            \n",
    "    return tmat\n",
    "\n",
    "def find_transformation(labels_im,anchor_round,downscale_factor = 1):\n",
    "\n",
    "    # resize the image\n",
    "    labels_small = labels_im>0\n",
    "    labels_small = downscale_local_mean(labels_small,(1,downscale_factor,downscale_factor))\n",
    "    \n",
    "    # find transformation\n",
    "    tf = StackReg.RIGID_BODY\n",
    "    sr = StackReg(tf)\n",
    "    \n",
    "    tmat_small = []\n",
    "    for frame in range(labels_small.shape[0]):\n",
    "\n",
    "        print(frame)\n",
    "        \n",
    "        if frame==anchor_round:\n",
    "            tmat_frame = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "        else:\n",
    "            tmat_frame = sr.register(labels_small[anchor_round],labels_small[frame])\n",
    "\n",
    "        tmat_small.append(tmat_frame)\n",
    "\n",
    "    tmat_small = np.asarray(tmat_small)\n",
    "\n",
    "    # rescale transformation\n",
    "    tmat = rescale_transforms(tmat_small,downscale_factor)\n",
    "            \n",
    "    return tmat,tmat_small\n",
    "\n",
    "def apply_transforms_set(tmat,movie):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for index,tranform_matrix in enumerate(tmat):\n",
    "    \n",
    "        eu_transform = transform.EuclideanTransform(tranform_matrix)\n",
    "\n",
    "        # if you want to check only transformation without rotation\n",
    "        #eu_transform_small = transform.EuclideanTransform(translation = eu_transform_small.translation, rotation = 0)\n",
    "\n",
    "        temp = transform.warp(movie[index,:,:],eu_transform,output_shape=movie[index].shape)\n",
    "\n",
    "        res.append(temp)\n",
    "\n",
    "    res = np.array(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing well D4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmkedz\\.conda\\envs\\napari-tests\\lib\\site-packages\\PIL\\Image.py:2896: DecompressionBombWarning: Image size (100721296 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label images 4\n",
      "Number of unique rounds 4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for myWell in well_list:\n",
    "    \n",
    "    print(f'Processing well {myWell}.')\n",
    "    \n",
    "    # read in the data\n",
    "    myData = pd.read_pickle(os.path.join(path_df,f'df_{myWell}.pkl'))\n",
    "    \n",
    "    # read in all the labels\n",
    "    labels_im = read_labels(path_labels,myWell)\n",
    "    \n",
    "    # check if you have an expected number of files to align\n",
    "    print(f'Number of label images {labels_im.shape[0]}')\n",
    "    print(f'Number of unique rounds {len(set(myData.alignRound))}')\n",
    "    \n",
    "    # check which alignRound for the anchor round\n",
    "    anchor_round = myData.loc[myData.nameRound == anchor_round_selected,'alignRound'].tolist()[0]\n",
    "    anchor_round = int(anchor_round)\n",
    "\n",
    "    # find transformation\n",
    "    tmat,tmat_small = find_transformation(labels_im,anchor_round,downscale_factor = downscale_factor)\n",
    "    \n",
    "    # save transformations\n",
    "    save_file_path = os.path.join(path_save,f'tmat_{myWell}.pkl')\n",
    "    pickle.dump(tmat, open(save_file_path, \"wb\"))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmkedz\\.conda\\envs\\napari-tests\\lib\\site-packages\\napari_tools_menu\\__init__.py:165: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'labels_small_aligned' at 0x2a4c0492880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test transformations\n",
    "\n",
    "# choose on which well to perform tests \n",
    "myWell = 'D4'\n",
    "\n",
    "# read in images\n",
    "labels_im = read_labels(path_labels,myWell)\n",
    "\n",
    "# read in transformation matrix\n",
    "tmat_list = pickle.load(open(os.path.join(path_save,f'tmat_{myWell}.pkl'), \"rb\"))\n",
    "tmat_small = rescale_transforms(tmat_list,1/downscale_factor)\n",
    "\n",
    "labels_small = downscale_local_mean(labels_im,(1,downscale_factor,downscale_factor))\n",
    "labels_small_aligned = apply_transforms_set(tmat_small,labels_small)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(labels_small[anchor_round],blending ='additive',colormap='gray')\n",
    "viewer.add_image(labels_small,blending ='additive',colormap='red')\n",
    "viewer.add_image(labels_small_aligned,blending ='additive',colormap='green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
